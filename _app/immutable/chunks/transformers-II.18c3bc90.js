import{S as un,i as mn,s as fn,G as o,K as r,C as c,H as p,f as i,L as l,g as e,D as u,_ as Ds,I as m,j as n,k as a,X as Xa}from"./vendor.eba8c6f3.js";function hn($t){let g,Ie,Gs,z,Re,zs,q,W,Za,qs,Ws,Vs,V,Ae,Bs,B,Pe,Ks,K,Le,Js,J,Se,Us,f,U,Es,Oe,Ce,Me,Y,_s,He,je,Fe,Q,xs,De,Ge,ze,X,Ns,qe,We,Ve,Z,Is,Be,Ke,Ys,d,Je,Rs,Ue,Ye,As,Qe,Xe,Ps,Ze,$e,Qs,$,sa,Xs,ss,N,es,$a,Zs,as,ea,$s,b,aa,Ls,ta,na,I,oa,pa,se,ts,ra,ee,ns,R,os,st,ae,ps,ia,te,T,la,A,ca,ua,ne,rs,ma,oe,is,fa,pe,v,ha,Ss,da,ka,Os,ba,va,re,h,wa,P,Cs,ya,ga,L,Ms,Ta,Ea,Hs,_a,xa,S,js,Na,Ia,ie,ls,Ra,le,cs,Aa,ce,us,Pa,ue,O,sn=`<code class="language-bash">pip <span class="token function">install</span> transformers  
pip <span class="token function">install</span> timm</code>`,me,C,en=`<code class="language-python"><span class="token comment"># Load the needed libraries to load images  </span>
<span class="token keyword">from</span> PIL <span class="token keyword">import</span> Image  
<span class="token keyword">import</span> requests

<span class="token comment"># In our case, we selected an image of a park  </span>
url <span class="token operator">=</span> <span class="token punctuation">(</span>
    <span class="token string">"https://www.burnaby.ca/sites/default/files/acquiadam/2021-06/"</span>
    <span class="token string">"Parks-Fraser-Foreshore.jpg"</span>
    <span class="token punctuation">)</span>

im <span class="token operator">=</span> Image<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span>requests<span class="token punctuation">.</span>get<span class="token punctuation">(</span>url<span class="token punctuation">,</span> stream<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">.</span>raw<span class="token punctuation">)</span>

<span class="token comment"># Show the image  </span>
im</code>`,fe,ms,fs,et,he,hs,La,de,M,an=`<code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> DetrFeatureExtractor

feature_extractor <span class="token operator">=</span> DetrFeatureExtractor<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>
    <span class="token string">"facebook/detr-resnet-50"</span>
<span class="token punctuation">)</span>

encoding <span class="token operator">=</span> feature_extractor<span class="token punctuation">(</span>im<span class="token punctuation">,</span> return_tensors<span class="token operator">=</span><span class="token string">"pt"</span><span class="token punctuation">)</span>

encoding<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span></code>`,ke,ds,Sa,be,H,tn=`<code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> DetrForObjectDetection

model <span class="token operator">=</span> DetrForObjectDetection<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>
    <span class="token string">"facebook/detr-resnet-50"</span>
<span class="token punctuation">)</span>

outputs <span class="token operator">=</span> model<span class="token punctuation">(</span><span class="token operator">**</span>encoding<span class="token punctuation">)</span></code>`,ve,ks,Oa,we,j,nn=`<code class="language-python"><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt

<span class="token comment"># colors for visualization</span>

COLORS <span class="token operator">=</span> <span class="token punctuation">[</span>
    <span class="token punctuation">[</span><span class="token number">0.000</span><span class="token punctuation">,</span> <span class="token number">0.447</span><span class="token punctuation">,</span> <span class="token number">0.741</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token punctuation">[</span><span class="token number">0.850</span><span class="token punctuation">,</span> <span class="token number">0.325</span><span class="token punctuation">,</span> <span class="token number">0.098</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token punctuation">[</span><span class="token number">0.929</span><span class="token punctuation">,</span> <span class="token number">0.694</span><span class="token punctuation">,</span> <span class="token number">0.125</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token punctuation">[</span><span class="token number">0.494</span><span class="token punctuation">,</span> <span class="token number">0.184</span><span class="token punctuation">,</span> <span class="token number">0.556</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token punctuation">[</span><span class="token number">0.466</span><span class="token punctuation">,</span> <span class="token number">0.674</span><span class="token punctuation">,</span> <span class="token number">0.188</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token punctuation">[</span><span class="token number">0.301</span><span class="token punctuation">,</span> <span class="token number">0.745</span><span class="token punctuation">,</span> <span class="token number">0.933</span><span class="token punctuation">]</span>
<span class="token punctuation">]</span>

<span class="token comment"># Define an auxiliary plotting function  </span>
<span class="token keyword">def</span> <span class="token function">plot_results</span><span class="token punctuation">(</span>pil_img<span class="token punctuation">,</span> prob<span class="token punctuation">,</span> boxes<span class="token punctuation">)</span><span class="token punctuation">:</span>

    plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  
    plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>pil_img<span class="token punctuation">)</span>

    ax <span class="token operator">=</span> plt<span class="token punctuation">.</span>gca<span class="token punctuation">(</span><span class="token punctuation">)</span>  
    colors <span class="token operator">=</span> COLORS <span class="token operator">*</span> <span class="token number">100</span>

    <span class="token keyword">for</span> p<span class="token punctuation">,</span> <span class="token punctuation">(</span>xmin<span class="token punctuation">,</span> ymin<span class="token punctuation">,</span> xmax<span class="token punctuation">,</span> ymax<span class="token punctuation">)</span><span class="token punctuation">,</span> c <span class="token keyword">in</span> <span class="token builtin">zip</span><span class="token punctuation">(</span>prob<span class="token punctuation">,</span> boxes<span class="token punctuation">.</span>tolist<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> colors<span class="token punctuation">)</span><span class="token punctuation">:</span>

        ax<span class="token punctuation">.</span>add_patch<span class="token punctuation">(</span>
            plt<span class="token punctuation">.</span>Rectangle<span class="token punctuation">(</span>
                <span class="token punctuation">(</span>xmin<span class="token punctuation">,</span> ymin<span class="token punctuation">)</span><span class="token punctuation">,</span>
                xmax <span class="token operator">-</span> xmin<span class="token punctuation">,</span>
                ymax <span class="token operator">-</span>ymin<span class="token punctuation">,</span>
                fill<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>
                color<span class="token operator">=</span>c<span class="token punctuation">,</span>
                linewidth<span class="token operator">=</span><span class="token number">3</span>
            <span class="token punctuation">)</span>
        <span class="token punctuation">)</span>

          cl <span class="token operator">=</span> p<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span><span class="token punctuation">)</span>
          text <span class="token operator">=</span> <span class="token string-interpolation"><span class="token string">f"</span><span class="token interpolation"><span class="token punctuation">&#123;</span>model<span class="token punctuation">.</span>config<span class="token punctuation">.</span>id2label<span class="token punctuation">[</span>cl<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">&#125;</span></span><span class="token string">: </span><span class="token interpolation"><span class="token punctuation">&#123;</span>p<span class="token punctuation">[</span>cl<span class="token punctuation">]</span><span class="token punctuation">:</span><span class="token format-spec">0.2f</span><span class="token punctuation">&#125;</span></span><span class="token string">"</span></span>
          ax<span class="token punctuation">.</span>text<span class="token punctuation">(</span>xmin<span class="token punctuation">,</span> ymin<span class="token punctuation">,</span> text<span class="token punctuation">,</span> fontsize<span class="token operator">=</span><span class="token number">15</span><span class="token punctuation">,</span>

          bbox<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>facecolor<span class="token operator">=</span><span class="token string">'yellow'</span><span class="token punctuation">,</span> alpha<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
          plt<span class="token punctuation">.</span>axis<span class="token punctuation">(</span><span class="token string">'off'</span><span class="token punctuation">)</span>
          plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">import</span> torch

<span class="token comment"># keep only predictions of queries with 0.9+ confidence (excluding</span>
<span class="token comment"># no-object class)  </span>
probas <span class="token operator">=</span> outputs<span class="token punctuation">.</span>logits<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>  
keep <span class="token operator">=</span> probas<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>values <span class="token operator">></span> <span class="token number">0.9</span>

<span class="token comment"># rescale bounding boxes</span>

target_sizes <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>im<span class="token punctuation">.</span>size<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>

postprocessed_outputs <span class="token operator">=</span> feature_extractor<span class="token punctuation">.</span>post_process<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> target_sizes<span class="token punctuation">)</span>

bboxes_scaled <span class="token operator">=</span> postprocessed_outputs<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'boxes'</span><span class="token punctuation">]</span><span class="token punctuation">[</span>keep<span class="token punctuation">]</span>

<span class="token comment"># Show the detection results  </span>
plot_results<span class="token punctuation">(</span>im<span class="token punctuation">,</span> probas<span class="token punctuation">[</span>keep<span class="token punctuation">]</span><span class="token punctuation">,</span> bboxes_scaled<span class="token punctuation">)</span></code>`,ye,bs,vs,at,ge,ws,Ca,Te,k,Ma,F,Ha,ja,D,Fa,Da,Fs,Ga,za,Ee,E,qa,G,Wa,Va,_e,ys,Ba;return{c(){g=o("h1"),Ie=r("TRANSFORMERS - multi-purpose AI models in disguise"),Gs=c(),z=o("h3"),Re=r("Novel applications of this powerful architecture set the bar for future AI advances"),zs=c(),q=o("p"),W=o("img"),qs=c(),Ws=o("hr"),Vs=c(),V=o("p"),Ae=r("In the first part of this article, we took a look at the Transformer model and its main use cases related to NLP, which have hopefully broadened your understanding of the topic at hand."),Bs=c(),B=o("p"),Pe=r("In the second part of this article, we will present novel model architectures and research employing Transformers in several fields unrelated to NLP, as well as showing some code examples of the capabilities of these remarkable new approaches."),Ks=c(),K=o("h3"),Le=r("HOW THE TRANSFORMER IS APPLIED TO OTHER AI TASKS"),Js=c(),J=o("p"),Se=r("As previously mentioned, the Transformer architecture provides a suitable framework designed to take advantage of long-term relationships between words. This allows the model to find patterns and meanings in the sentences and makes it suited for many tasks in NLP. The most common ones are:"),Us=c(),f=o("ul"),U=o("li"),Es=o("strong"),Oe=r("Text classification"),Ce=r(" into categories, such as obtaining the sentiment of a text."),Me=c(),Y=o("li"),_s=o("strong"),He=r("Question answering"),je=r(", where the model can extract information from a text when prompted to do so."),Fe=c(),Q=o("li"),xs=o("strong"),De=r("Text generation"),Ge=r(", such as GPT-3."),ze=c(),X=o("li"),Ns=o("strong"),qe=r("Translation"),We=r("; Google Translate already employs this technology."),Ve=c(),Z=o("li"),Is=o("strong"),Be=r("Summarization"),Ke=r(" of a text into few words or sentences."),Ys=c(),d=o("p"),Je=r("After the success of the Transformer model applied to NLP tasks, people began to wonder: If it can find long-term relationships in the data and be trained efficiently, then "),Rs=o("strong"),Ue=r("could it be as efficient in other tasks besides NLP"),Ye=r("? This is the start of the current movement of research, where this model is used as the "),As=o("em"),Qe=r("backbone"),Xe=r(" for many algorithms in AI and "),Ps=o("em"),Ze=r("machine learning"),$e=r(" previously dominated by other techniques. Some amazing contributions in other AI fields are:"),Qs=c(),$=o("h4"),sa=r("Lip reading and text transcription"),Xs=c(),ss=o("p"),N=o("a"),es=o("img"),Zs=c(),as=o("p"),ea=r("A recurring problem in society is related to the transcription of texts, especially for hearing impaired people. The current advances are divided into two groups: using an audio track and transcribing it, or directly interpreting the words from the person’s lip movements. The latter problem is a lot harder to resolve since many factors are involved."),$s=c(),b=o("p"),aa=r("Potentially, this solution could provide help in situations where recording audio is impossible, such as in noisy areas. In this regard, most researchers use CNN or LSTM as the main model interpreting this as a pure "),Ls=o("em"),ta=r("Computer Vision"),na=r(" task. Recently, some "),I=o("a"),oa=r("studies"),pa=r(" have been published where Transformer-based solutions to this problem are presented, providing better results than the current state-of-the-art solutions."),se=c(),ts=o("h4"),ra=r("Traffic route prediction at sea"),ee=c(),ns=o("p"),R=o("a"),os=o("img"),ae=c(),ps=o("p"),ia=r("One of the main focuses of AI models is the prediction of routes, either for individual people or traffic. However, in this regard, the models employed are mostly trained on land traffic since it is easier to obtain data and model it. Regarding sea traffic, the scarcity and dependence on external factors such as weather or sea currents makes it more difficult to provide accurate predictions for the next few hours."),te=c(),T=o("p"),la=r("Most of the employed models rely on LSTM or CNN for the same previous reasons, but these models struggle when dealing with long-term predictions and they don’t take into account the specific characteristics of data obtained at sea. A recent "),A=o("a"),ca=r("study"),ua=r(" presents a novel algorithm that takes into account the data’s nuances and provides a vessel trajectory prediction using a Transformer model. The accuracy of the predictions is well above the alternative models available, where long-term predictions are mandatory."),ne=c(),rs=o("h4"),ma=r("Object detection"),oe=c(),is=o("p"),fa=r("This is a subset of Computer Vision and one of the most common AI tasks. In this task, the model can detect certain objects in an image or video and draw a box around them; some common examples are your phone’s face recognition functionality when you take a picture or unlock it, or CCTV detection of license plates."),pe=c(),v=o("p"),ha=r("In this regard, the models that have been employed in the past are mostly based on CNN since these excel at finding relationships in images; the most common ones being "),Ss=o("em"),da=r("SSD"),ka=r(" and "),Os=o("em"),ba=r("Faster R-CNN"),va=r(". As a result, most algorithms currently used in these tasks have some variation of this model architecture."),re=c(),h=o("p"),wa=r("However, as was the case for the other tasks, the Transformer architecture has also been experimented with for finding patterns in images. This has lead to several approaches where CNN and Transformer are used jointly, like Facebook’s "),P=o("a"),Cs=o("strong"),ya=r("DETR"),ga=r(", or purely Transformer-based architectures like "),L=o("a"),Ms=o("strong"),Ta=r("Vision Transformer"),Ea=r(". The most impactful research in the past few months has been the novel approach of "),Hs=o("em"),_a=r("shifted windows"),xa=r(" in the "),S=o("a"),js=o("strong"),Na=r("Swin Transformer"),Ia=r(", achieving cutting-edge results on a number of categories involving image analysis."),ie=c(),ls=o("h4"),Ra=r("LEARN BY SEEING: OBJECT DETECTION WITH DETR"),le=c(),cs=o("p"),Aa=r("For most of these models, the code and training data are publicly available and open-sourced, which eases their use for inference and fine-tuning. As an example, we will show below how to load and use the DETR model for a specific image."),ce=c(),us=o("p"),Pa=r("First, install the dependencies and load an image of your choosing using its URL:"),ue=c(),O=o("pre"),me=c(),C=o("pre"),fe=c(),ms=o("p"),fs=o("img"),he=c(),hs=o("p"),La=r("Then, we apply the feature extractor to resize and normalize the image so the model can interpret it correctly. This will use the simplest DETR model, with the ResNet-50 backbone:"),de=c(),M=o("pre"),ke=c(),ds=o("p"),Sa=r("Next, load the pre-trained model and pass the image through:"),be=c(),H=o("pre"),ve=c(),ks=o("p"),Oa=r("And that’s it! Now we only have to interpret the results and represent the detected objects with some boxes:"),we=c(),j=o("pre"),ye=c(),bs=o("p"),vs=o("img"),ge=c(),ws=o("p"),Ca=r("Bounding boxes appear around each object, where the value indicates the detection confidence."),Te=c(),k=o("p"),Ma=r("The accuracy of these models is remarkable! Even smaller objects, which are harder to detect for the usual neural networks, are identified correctly. Thank you "),F=o("a"),Ha=r("Niels Rogge"),ja=r(" for the awesome "),D=o("a"),Fa=r("implementation"),Da=r(" of these models in the "),Fs=o("em"),Ga=r("Transformers"),za=r(" library!"),Ee=c(),E=o("p"),qa=r("These examples are just the tip of the iceberg of this research movement. The high flexibility of this architecture and the numerous advantages provided are well suited for a number of AI tasks, and multiple advances are being made on a daily basis on multiple fronts. Recently, Facebook AI published a new paper presenting the scalability of these models for CV tasks that has stirred the community quite a bit; you can also check it out "),G=o("a"),Wa=r("here"),Va=r("."),_e=c(),ys=o("p"),Ba=r("Will this be the future of all AI models? Is the Transformer the best solution for all tasks, or will it be resigned to its NLP applications? One thing is for sure: For the time being, the Transformer is here to stay!"),this.h()},l(s){g=p(s,"H1",{});var t=i(g);Ie=l(t,"TRANSFORMERS - multi-purpose AI models in disguise"),t.forEach(e),Gs=u(s),z=p(s,"H3",{});var tt=i(z);Re=l(tt,"Novel applications of this powerful architecture set the bar for future AI advances"),tt.forEach(e),zs=u(s),q=p(s,"P",{});var nt=i(q);W=p(nt,"IMG",{src:!0,alt:!0}),nt.forEach(e),qs=u(s),Ws=p(s,"HR",{}),Vs=u(s),V=p(s,"P",{});var ot=i(V);Ae=l(ot,"In the first part of this article, we took a look at the Transformer model and its main use cases related to NLP, which have hopefully broadened your understanding of the topic at hand."),ot.forEach(e),Bs=u(s),B=p(s,"P",{});var pt=i(B);Pe=l(pt,"In the second part of this article, we will present novel model architectures and research employing Transformers in several fields unrelated to NLP, as well as showing some code examples of the capabilities of these remarkable new approaches."),pt.forEach(e),Ks=u(s),K=p(s,"H3",{});var rt=i(K);Le=l(rt,"HOW THE TRANSFORMER IS APPLIED TO OTHER AI TASKS"),rt.forEach(e),Js=u(s),J=p(s,"P",{});var it=i(J);Se=l(it,"As previously mentioned, the Transformer architecture provides a suitable framework designed to take advantage of long-term relationships between words. This allows the model to find patterns and meanings in the sentences and makes it suited for many tasks in NLP. The most common ones are:"),it.forEach(e),Us=u(s),f=p(s,"UL",{});var w=i(f);U=p(w,"LI",{});var Ka=i(U);Es=p(Ka,"STRONG",{});var lt=i(Es);Oe=l(lt,"Text classification"),lt.forEach(e),Ce=l(Ka," into categories, such as obtaining the sentiment of a text."),Ka.forEach(e),Me=u(w),Y=p(w,"LI",{});var Ja=i(Y);_s=p(Ja,"STRONG",{});var ct=i(_s);He=l(ct,"Question answering"),ct.forEach(e),je=l(Ja,", where the model can extract information from a text when prompted to do so."),Ja.forEach(e),Fe=u(w),Q=p(w,"LI",{});var Ua=i(Q);xs=p(Ua,"STRONG",{});var ut=i(xs);De=l(ut,"Text generation"),ut.forEach(e),Ge=l(Ua,", such as GPT-3."),Ua.forEach(e),ze=u(w),X=p(w,"LI",{});var Ya=i(X);Ns=p(Ya,"STRONG",{});var mt=i(Ns);qe=l(mt,"Translation"),mt.forEach(e),We=l(Ya,"; Google Translate already employs this technology."),Ya.forEach(e),Ve=u(w),Z=p(w,"LI",{});var Qa=i(Z);Is=p(Qa,"STRONG",{});var ft=i(Is);Be=l(ft,"Summarization"),ft.forEach(e),Ke=l(Qa," of a text into few words or sentences."),Qa.forEach(e),w.forEach(e),Ys=u(s),d=p(s,"P",{});var _=i(d);Je=l(_,"After the success of the Transformer model applied to NLP tasks, people began to wonder: If it can find long-term relationships in the data and be trained efficiently, then "),Rs=p(_,"STRONG",{});var ht=i(Rs);Ue=l(ht,"could it be as efficient in other tasks besides NLP"),ht.forEach(e),Ye=l(_,"? This is the start of the current movement of research, where this model is used as the "),As=p(_,"EM",{});var dt=i(As);Qe=l(dt,"backbone"),dt.forEach(e),Xe=l(_," for many algorithms in AI and "),Ps=p(_,"EM",{});var kt=i(Ps);Ze=l(kt,"machine learning"),kt.forEach(e),$e=l(_," previously dominated by other techniques. Some amazing contributions in other AI fields are:"),_.forEach(e),Qs=u(s),$=p(s,"H4",{});var bt=i($);sa=l(bt,"Lip reading and text transcription"),bt.forEach(e),Xs=u(s),ss=p(s,"P",{});var vt=i(ss);N=p(vt,"A",{href:!0,rel:!0});var wt=i(N);es=p(wt,"IMG",{src:!0,alt:!0}),wt.forEach(e),vt.forEach(e),Zs=u(s),as=p(s,"P",{});var yt=i(as);ea=l(yt,"A recurring problem in society is related to the transcription of texts, especially for hearing impaired people. The current advances are divided into two groups: using an audio track and transcribing it, or directly interpreting the words from the person’s lip movements. The latter problem is a lot harder to resolve since many factors are involved."),yt.forEach(e),$s=u(s),b=p(s,"P",{});var gs=i(b);aa=l(gs,"Potentially, this solution could provide help in situations where recording audio is impossible, such as in noisy areas. In this regard, most researchers use CNN or LSTM as the main model interpreting this as a pure "),Ls=p(gs,"EM",{});var gt=i(Ls);ta=l(gt,"Computer Vision"),gt.forEach(e),na=l(gs," task. Recently, some "),I=p(gs,"A",{href:!0,rel:!0});var Tt=i(I);oa=l(Tt,"studies"),Tt.forEach(e),pa=l(gs," have been published where Transformer-based solutions to this problem are presented, providing better results than the current state-of-the-art solutions."),gs.forEach(e),se=u(s),ts=p(s,"H4",{});var Et=i(ts);ra=l(Et,"Traffic route prediction at sea"),Et.forEach(e),ee=u(s),ns=p(s,"P",{});var _t=i(ns);R=p(_t,"A",{href:!0,rel:!0});var xt=i(R);os=p(xt,"IMG",{src:!0,alt:!0}),xt.forEach(e),_t.forEach(e),ae=u(s),ps=p(s,"P",{});var Nt=i(ps);ia=l(Nt,"One of the main focuses of AI models is the prediction of routes, either for individual people or traffic. However, in this regard, the models employed are mostly trained on land traffic since it is easier to obtain data and model it. Regarding sea traffic, the scarcity and dependence on external factors such as weather or sea currents makes it more difficult to provide accurate predictions for the next few hours."),Nt.forEach(e),te=u(s),T=p(s,"P",{});var xe=i(T);la=l(xe,"Most of the employed models rely on LSTM or CNN for the same previous reasons, but these models struggle when dealing with long-term predictions and they don’t take into account the specific characteristics of data obtained at sea. A recent "),A=p(xe,"A",{href:!0,rel:!0});var It=i(A);ca=l(It,"study"),It.forEach(e),ua=l(xe," presents a novel algorithm that takes into account the data’s nuances and provides a vessel trajectory prediction using a Transformer model. The accuracy of the predictions is well above the alternative models available, where long-term predictions are mandatory."),xe.forEach(e),ne=u(s),rs=p(s,"H4",{});var Rt=i(rs);ma=l(Rt,"Object detection"),Rt.forEach(e),oe=u(s),is=p(s,"P",{});var At=i(is);fa=l(At,"This is a subset of Computer Vision and one of the most common AI tasks. In this task, the model can detect certain objects in an image or video and draw a box around them; some common examples are your phone’s face recognition functionality when you take a picture or unlock it, or CCTV detection of license plates."),At.forEach(e),pe=u(s),v=p(s,"P",{});var Ts=i(v);ha=l(Ts,"In this regard, the models that have been employed in the past are mostly based on CNN since these excel at finding relationships in images; the most common ones being "),Ss=p(Ts,"EM",{});var Pt=i(Ss);da=l(Pt,"SSD"),Pt.forEach(e),ka=l(Ts," and "),Os=p(Ts,"EM",{});var Lt=i(Os);ba=l(Lt,"Faster R-CNN"),Lt.forEach(e),va=l(Ts,". As a result, most algorithms currently used in these tasks have some variation of this model architecture."),Ts.forEach(e),re=u(s),h=p(s,"P",{});var y=i(h);wa=l(y,"However, as was the case for the other tasks, the Transformer architecture has also been experimented with for finding patterns in images. This has lead to several approaches where CNN and Transformer are used jointly, like Facebook’s "),P=p(y,"A",{href:!0,rel:!0});var St=i(P);Cs=p(St,"STRONG",{});var Ot=i(Cs);ya=l(Ot,"DETR"),Ot.forEach(e),St.forEach(e),ga=l(y,", or purely Transformer-based architectures like "),L=p(y,"A",{href:!0,rel:!0});var Ct=i(L);Ms=p(Ct,"STRONG",{});var Mt=i(Ms);Ta=l(Mt,"Vision Transformer"),Mt.forEach(e),Ct.forEach(e),Ea=l(y,". The most impactful research in the past few months has been the novel approach of "),Hs=p(y,"EM",{});var Ht=i(Hs);_a=l(Ht,"shifted windows"),Ht.forEach(e),xa=l(y," in the "),S=p(y,"A",{href:!0,rel:!0});var jt=i(S);js=p(jt,"STRONG",{});var Ft=i(js);Na=l(Ft,"Swin Transformer"),Ft.forEach(e),jt.forEach(e),Ia=l(y,", achieving cutting-edge results on a number of categories involving image analysis."),y.forEach(e),ie=u(s),ls=p(s,"H4",{});var Dt=i(ls);Ra=l(Dt,"LEARN BY SEEING: OBJECT DETECTION WITH DETR"),Dt.forEach(e),le=u(s),cs=p(s,"P",{});var Gt=i(cs);Aa=l(Gt,"For most of these models, the code and training data are publicly available and open-sourced, which eases their use for inference and fine-tuning. As an example, we will show below how to load and use the DETR model for a specific image."),Gt.forEach(e),ce=u(s),us=p(s,"P",{});var zt=i(us);Pa=l(zt,"First, install the dependencies and load an image of your choosing using its URL:"),zt.forEach(e),ue=u(s),O=p(s,"PRE",{class:!0});var on=i(O);on.forEach(e),me=u(s),C=p(s,"PRE",{class:!0});var pn=i(C);pn.forEach(e),fe=u(s),ms=p(s,"P",{});var qt=i(ms);fs=p(qt,"IMG",{src:!0,alt:!0}),qt.forEach(e),he=u(s),hs=p(s,"P",{});var Wt=i(hs);La=l(Wt,"Then, we apply the feature extractor to resize and normalize the image so the model can interpret it correctly. This will use the simplest DETR model, with the ResNet-50 backbone:"),Wt.forEach(e),de=u(s),M=p(s,"PRE",{class:!0});var rn=i(M);rn.forEach(e),ke=u(s),ds=p(s,"P",{});var Vt=i(ds);Sa=l(Vt,"Next, load the pre-trained model and pass the image through:"),Vt.forEach(e),be=u(s),H=p(s,"PRE",{class:!0});var ln=i(H);ln.forEach(e),ve=u(s),ks=p(s,"P",{});var Bt=i(ks);Oa=l(Bt,"And that’s it! Now we only have to interpret the results and represent the detected objects with some boxes:"),Bt.forEach(e),we=u(s),j=p(s,"PRE",{class:!0});var cn=i(j);cn.forEach(e),ye=u(s),bs=p(s,"P",{});var Kt=i(bs);vs=p(Kt,"IMG",{src:!0,alt:!0}),Kt.forEach(e),ge=u(s),ws=p(s,"P",{});var Jt=i(ws);Ca=l(Jt,"Bounding boxes appear around each object, where the value indicates the detection confidence."),Jt.forEach(e),Te=u(s),k=p(s,"P",{});var x=i(k);Ma=l(x,"The accuracy of these models is remarkable! Even smaller objects, which are harder to detect for the usual neural networks, are identified correctly. Thank you "),F=p(x,"A",{href:!0,rel:!0});var Ut=i(F);Ha=l(Ut,"Niels Rogge"),Ut.forEach(e),ja=l(x," for the awesome "),D=p(x,"A",{href:!0,rel:!0});var Yt=i(D);Fa=l(Yt,"implementation"),Yt.forEach(e),Da=l(x," of these models in the "),Fs=p(x,"EM",{});var Qt=i(Fs);Ga=l(Qt,"Transformers"),Qt.forEach(e),za=l(x," library!"),x.forEach(e),Ee=u(s),E=p(s,"P",{});var Ne=i(E);qa=l(Ne,"These examples are just the tip of the iceberg of this research movement. The high flexibility of this architecture and the numerous advantages provided are well suited for a number of AI tasks, and multiple advances are being made on a daily basis on multiple fronts. Recently, Facebook AI published a new paper presenting the scalability of these models for CV tasks that has stirred the community quite a bit; you can also check it out "),G=p(Ne,"A",{href:!0,rel:!0});var Xt=i(G);Wa=l(Xt,"here"),Xt.forEach(e),Va=l(Ne,"."),Ne.forEach(e),_e=u(s),ys=p(s,"P",{});var Zt=i(ys);Ba=l(Zt,"Will this be the future of all AI models? Is the Transformer the best solution for all tasks, or will it be resigned to its NLP applications? One thing is for sure: For the time being, the Transformer is here to stay!"),Zt.forEach(e),this.h()},h(){Ds(W.src,Za="https://cdn-images-1.medium.com/max/1200/1*-EKJaNY5il-iA-ytWc1HOw.jpeg")||m(W,"src",Za),m(W,"alt","Abstract wordcloud"),Ds(es.src,$a="https://cdn-images-1.medium.com/max/800/0*WsXnjjFjvkLUAXdk")||m(es,"src",$a),m(es,"alt","Lip reading"),m(N,"href","https://media.istockphoto.com/photos/woman-talking-with-alphabet-letters-coming-out-of-her-mouth-concept-picture-id675298456?k=20&m=675298456&s=612x612&w=0&h=0mIKvq4llWoxK2knLbqTqHLgclra6LCbD1mGkMlf3n0="),m(N,"rel","nofollow"),m(I,"href","https://ieeexplore.ieee.org/document/9172849"),m(I,"rel","nofollow"),Ds(os.src,st="https://cdn-images-1.medium.com/max/800/0*Puld-s2tGeyF5Hg6")||m(os,"src",st),m(os,"alt","Maritime traffic density map as of the year 2015."),m(R,"href","https://www.researchgate.net/figure/2015-worldwide-maritime-traffic-density-map-The-density-is-evaluated-as-the-number-of_fig1_317201419"),m(R,"rel","nofollow"),m(A,"href","https://arxiv.org/abs/2109.03958"),m(A,"rel","nofollow"),m(P,"href","https://arxiv.org/abs/2005.12872"),m(P,"rel","nofollow"),m(L,"href","https://arxiv.org/abs/2010.11929"),m(L,"rel","nofollow"),m(S,"href","https://arxiv.org/abs/2103.14030"),m(S,"rel","nofollow"),m(O,"class","language-bash"),m(C,"class","language-python"),Ds(fs.src,et="https://cdn-images-1.medium.com/max/800/0*skxNs07GaWuj_CCm")||m(fs,"src",et),m(fs,"alt","Park with people during the day"),m(M,"class","language-python"),m(H,"class","language-python"),m(j,"class","language-python"),Ds(vs.src,at="https://cdn-images-1.medium.com/max/800/0*4vUBdKuSJoWvQgqB")||m(vs,"src",at),m(vs,"alt","DETR object detection output with bounding boxes"),m(F,"href","https://github.com/NielsRogge"),m(F,"rel","nofollow"),m(D,"href","https://github.com/NielsRogge/Transformers-Tutorials"),m(D,"rel","nofollow"),m(G,"href","https://medium.com/syncedreview/a-leap-forward-in-computer-vision-facebook-ai-says-masked-autoencoders-are-scalable-vision-32c08fadd41f"),m(G,"rel","nofollow")},m(s,t){n(s,g,t),a(g,Ie),n(s,Gs,t),n(s,z,t),a(z,Re),n(s,zs,t),n(s,q,t),a(q,W),n(s,qs,t),n(s,Ws,t),n(s,Vs,t),n(s,V,t),a(V,Ae),n(s,Bs,t),n(s,B,t),a(B,Pe),n(s,Ks,t),n(s,K,t),a(K,Le),n(s,Js,t),n(s,J,t),a(J,Se),n(s,Us,t),n(s,f,t),a(f,U),a(U,Es),a(Es,Oe),a(U,Ce),a(f,Me),a(f,Y),a(Y,_s),a(_s,He),a(Y,je),a(f,Fe),a(f,Q),a(Q,xs),a(xs,De),a(Q,Ge),a(f,ze),a(f,X),a(X,Ns),a(Ns,qe),a(X,We),a(f,Ve),a(f,Z),a(Z,Is),a(Is,Be),a(Z,Ke),n(s,Ys,t),n(s,d,t),a(d,Je),a(d,Rs),a(Rs,Ue),a(d,Ye),a(d,As),a(As,Qe),a(d,Xe),a(d,Ps),a(Ps,Ze),a(d,$e),n(s,Qs,t),n(s,$,t),a($,sa),n(s,Xs,t),n(s,ss,t),a(ss,N),a(N,es),n(s,Zs,t),n(s,as,t),a(as,ea),n(s,$s,t),n(s,b,t),a(b,aa),a(b,Ls),a(Ls,ta),a(b,na),a(b,I),a(I,oa),a(b,pa),n(s,se,t),n(s,ts,t),a(ts,ra),n(s,ee,t),n(s,ns,t),a(ns,R),a(R,os),n(s,ae,t),n(s,ps,t),a(ps,ia),n(s,te,t),n(s,T,t),a(T,la),a(T,A),a(A,ca),a(T,ua),n(s,ne,t),n(s,rs,t),a(rs,ma),n(s,oe,t),n(s,is,t),a(is,fa),n(s,pe,t),n(s,v,t),a(v,ha),a(v,Ss),a(Ss,da),a(v,ka),a(v,Os),a(Os,ba),a(v,va),n(s,re,t),n(s,h,t),a(h,wa),a(h,P),a(P,Cs),a(Cs,ya),a(h,ga),a(h,L),a(L,Ms),a(Ms,Ta),a(h,Ea),a(h,Hs),a(Hs,_a),a(h,xa),a(h,S),a(S,js),a(js,Na),a(h,Ia),n(s,ie,t),n(s,ls,t),a(ls,Ra),n(s,le,t),n(s,cs,t),a(cs,Aa),n(s,ce,t),n(s,us,t),a(us,Pa),n(s,ue,t),n(s,O,t),O.innerHTML=sn,n(s,me,t),n(s,C,t),C.innerHTML=en,n(s,fe,t),n(s,ms,t),a(ms,fs),n(s,he,t),n(s,hs,t),a(hs,La),n(s,de,t),n(s,M,t),M.innerHTML=an,n(s,ke,t),n(s,ds,t),a(ds,Sa),n(s,be,t),n(s,H,t),H.innerHTML=tn,n(s,ve,t),n(s,ks,t),a(ks,Oa),n(s,we,t),n(s,j,t),j.innerHTML=nn,n(s,ye,t),n(s,bs,t),a(bs,vs),n(s,ge,t),n(s,ws,t),a(ws,Ca),n(s,Te,t),n(s,k,t),a(k,Ma),a(k,F),a(F,Ha),a(k,ja),a(k,D),a(D,Fa),a(k,Da),a(k,Fs),a(Fs,Ga),a(k,za),n(s,Ee,t),n(s,E,t),a(E,qa),a(E,G),a(G,Wa),a(E,Va),n(s,_e,t),n(s,ys,t),a(ys,Ba)},p:Xa,i:Xa,o:Xa,d(s){s&&e(g),s&&e(Gs),s&&e(z),s&&e(zs),s&&e(q),s&&e(qs),s&&e(Ws),s&&e(Vs),s&&e(V),s&&e(Bs),s&&e(B),s&&e(Ks),s&&e(K),s&&e(Js),s&&e(J),s&&e(Us),s&&e(f),s&&e(Ys),s&&e(d),s&&e(Qs),s&&e($),s&&e(Xs),s&&e(ss),s&&e(Zs),s&&e(as),s&&e($s),s&&e(b),s&&e(se),s&&e(ts),s&&e(ee),s&&e(ns),s&&e(ae),s&&e(ps),s&&e(te),s&&e(T),s&&e(ne),s&&e(rs),s&&e(oe),s&&e(is),s&&e(pe),s&&e(v),s&&e(re),s&&e(h),s&&e(ie),s&&e(ls),s&&e(le),s&&e(cs),s&&e(ce),s&&e(us),s&&e(ue),s&&e(O),s&&e(me),s&&e(C),s&&e(fe),s&&e(ms),s&&e(he),s&&e(hs),s&&e(de),s&&e(M),s&&e(ke),s&&e(ds),s&&e(be),s&&e(H),s&&e(ve),s&&e(ks),s&&e(we),s&&e(j),s&&e(ye),s&&e(bs),s&&e(ge),s&&e(ws),s&&e(Te),s&&e(k),s&&e(Ee),s&&e(E),s&&e(_e),s&&e(ys)}}}const kn={title:"TRANSFORMERS - multi-purpose AI models in disguise (Part II)",subtitle:"Second part of the post series delving into the Transformer architecture and its applications outside of NLP.",date:"2022-01-10",thumbnail_url:"https://miro.medium.com/v2/format:webp/1*-EKJaNY5il-iA-ytWc1HOw.jpeg",thumbnail_alt:"Transformers outside NLP",media:"Posted on Medium"};class bn extends un{constructor(g){super(),mn(this,g,null,hn,fn,{})}}export{bn as default,kn as metadata};
